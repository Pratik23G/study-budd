"""Inference module for LLM API integration.

This module handles:
- LLM client configuration and calls
- Prompt templates and system prompts
- Response parsing and error handling
"""
